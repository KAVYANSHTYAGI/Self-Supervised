{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAVYANSHTYAGI/Self-Supervised/blob/main/SimCLR_cifar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybzCb1H_QBB1",
        "outputId": "9640a242-9966-4862-b0dc-45d89dd13276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:27<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.0120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:28<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 0.0088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:30<00:00,  1.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 0.0049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:28<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 0.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:28<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 0.0027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:28<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 0.0020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:28<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 0.0019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:28<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 0.0014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:29<00:00,  1.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 0.0019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [04:29<00:00,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 0.0022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# SimCLR Augmentations with stronger transformations\n",
        "def get_transforms():\n",
        "    return transforms.Compose([\n",
        "        transforms.RandomResizedCrop(32, scale=(0.2, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.8, 0.8, 0.8, 0.2),\n",
        "        transforms.RandomGrayscale(p=0.2),\n",
        "        transforms.GaussianBlur(kernel_size=5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "# Load Dataset (CIFAR-10 for now)\n",
        "def get_dataset():\n",
        "    transform = get_transforms()\n",
        "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "    return DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4)\n",
        "\n",
        "# Improved Projection Head with BatchNorm\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, input_dim=512, proj_dim=128):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 1024)\n",
        "        self.bn1 = nn.BatchNorm1d(1024)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(1024, proj_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(proj_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        return F.normalize(x, dim=1)\n",
        "\n",
        "# SimCLR Model\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, backbone, projection_dim=128):\n",
        "        super().__init__()\n",
        "        self.encoder = backbone\n",
        "        self.projection_head = ProjectionHead(input_dim=512, proj_dim=projection_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z = self.projection_head(h)\n",
        "        return z\n",
        "\n",
        "# Updated Contrastive Loss with Lower Temperature\n",
        "def contrastive_loss(z_i, z_j, temperature=0.07):\n",
        "    batch_size = z_i.shape[0]\n",
        "    z = torch.cat([z_i, z_j], dim=0)\n",
        "    similarity_matrix = torch.mm(z, z.T) / temperature\n",
        "\n",
        "    mask = torch.eye(2 * batch_size, dtype=torch.bool).to(z.device)\n",
        "    similarity_matrix.masked_fill_(mask, float('-inf'))\n",
        "\n",
        "    labels = torch.cat([torch.arange(batch_size) for _ in range(2)], dim=0).to(z.device)\n",
        "    labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
        "\n",
        "    loss = -torch.log((similarity_matrix.exp() * labels).sum(dim=1) / similarity_matrix.exp().sum(dim=1))\n",
        "    return loss.mean()\n",
        "\n",
        "# Training\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load Data\n",
        "    train_loader = get_dataset()\n",
        "\n",
        "    # Define Model\n",
        "    resnet = torchvision.models.resnet18(pretrained=False)\n",
        "    resnet.fc = nn.Identity()  # Remove classification head\n",
        "    model = SimCLR(resnet).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-6)\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(10):  # Train for 10 epochs first\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for (x, _) in tqdm(train_loader):\n",
        "            x1, x2 = x.to(device), x.to(device)  # Augmentations applied twice\n",
        "\n",
        "            z1, z2 = model(x1), model(x2)\n",
        "            loss = contrastive_loss(z1, z2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow"
      ],
      "metadata": {
        "id": "hvCf2pAjaK-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa  # For potential Gaussian blur (if needed)\n",
        "import math\n",
        "\n",
        "# 1. Data Augmentations (SimCLR style)\n",
        "def random_resized_crop(image, crop_size=32, scale=(0.2, 1.0)):\n",
        "    \"\"\"Randomly crops and resizes the image.\"\"\"\n",
        "    # Determine scale factor randomly\n",
        "    shape = tf.shape(image)\n",
        "    height, width = shape[0], shape[1]\n",
        "    scale_factor = tf.random.uniform([], scale[0], scale[1])\n",
        "    new_size = tf.cast(tf.cast(tf.minimum(height, width), tf.float32) * scale_factor, tf.int32)\n",
        "    # Random crop then resize back to crop_size x crop_size\n",
        "    image = tf.image.random_crop(image, size=[new_size, new_size, 3])\n",
        "    image = tf.image.resize(image, (crop_size, crop_size))\n",
        "    return image\n",
        "\n",
        "def color_jitter(image, brightness=0.8, contrast=0.8, saturation=0.8, hue=0.2):\n",
        "    image = tf.image.random_brightness(image, max_delta=brightness)\n",
        "    image = tf.image.random_contrast(image, lower=1-contrast, upper=1+contrast)\n",
        "    image = tf.image.random_saturation(image, lower=1-saturation, upper=1+saturation)\n",
        "    image = tf.image.random_hue(image, max_delta=hue)\n",
        "    return image\n",
        "\n",
        "def random_grayscale(image, p=0.2):\n",
        "    def to_grayscale():\n",
        "        gray = tf.image.rgb_to_grayscale(image)\n",
        "        return tf.image.grayscale_to_rgb(gray)\n",
        "    return tf.cond(tf.less(tf.random.uniform([], 0, 1), p), to_grayscale, lambda: image)\n",
        "\n",
        "def gaussian_blur(image, kernel_size=5, sigma=1.0):\n",
        "    \"\"\"Applies Gaussian blur using a depthwise conv.\n",
        "    This is a simple approximation; tensorflow-addons also offers image filtering.\"\"\"\n",
        "    # Create 1D Gaussian kernel\n",
        "    radius = kernel_size // 2\n",
        "    x = tf.range(-radius, radius + 1, dtype=tf.float32)\n",
        "    blur_filter = tf.exp(-0.5 * (x / sigma) ** 2)\n",
        "    blur_filter = blur_filter / tf.reduce_sum(blur_filter)\n",
        "    # Reshape kernels for separable conv2d\n",
        "    blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
        "    blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
        "    # Expand image dims to [1, h, w, c]\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    channels = tf.shape(image)[-1]\n",
        "    # Apply vertical and horizontal blur separately\n",
        "    image = tf.nn.depthwise_conv2d(image, tf.repeat(blur_v, channels, axis=2), strides=[1, 1, 1, 1], padding='SAME')\n",
        "    image = tf.nn.depthwise_conv2d(image, tf.repeat(blur_h, channels, axis=2), strides=[1, 1, 1, 1], padding='SAME')\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "    return image\n",
        "\n",
        "def normalize(image):\n",
        "    # Normalize to mean=0.5, std=0.5 per channel assuming image is in [0,1]\n",
        "    return (image - 0.5) / 0.5\n",
        "\n",
        "def simclr_augment(image):\n",
        "    # Convert image type and scale to [0,1]\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = random_resized_crop(image, crop_size=32)\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = color_jitter(image)\n",
        "    image = random_grayscale(image, p=0.2)\n",
        "    image = gaussian_blur(image, kernel_size=5, sigma=1.0)\n",
        "    image = normalize(image)\n",
        "    return image\n",
        "\n",
        "def two_augmentations(image):\n",
        "    # Create two differently augmented versions of the same image\n",
        "    return simclr_augment(image), simclr_augment(image)\n",
        "\n",
        "# 2. Dataset Preparation (CIFAR-10)\n",
        "def prepare_dataset(batch_size=256):\n",
        "    (x_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "    dataset = dataset.shuffle(buffer_size=10000)\n",
        "    # For each image, get two augmentations\n",
        "    dataset = dataset.map(lambda x: two_augmentations(x), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# 3. Projection Head with BatchNorm\n",
        "class ProjectionHead(tf.keras.Model):\n",
        "    def __init__(self, input_dim=512, proj_dim=128):\n",
        "        super(ProjectionHead, self).__init__()\n",
        "        self.dense1 = layers.Dense(1024)\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        self.dense2 = layers.Dense(proj_dim)\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.dense1(x)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = self.relu(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        # L2 normalization along feature dimension\n",
        "        x = tf.math.l2_normalize(x, axis=1)\n",
        "        return x\n",
        "\n",
        "# 4. SimCLR Model\n",
        "def get_backbone():\n",
        "    # Using a simple ResNet-like model. Here we use a ResNet50 without the top layer.\n",
        "    base_model = tf.keras.applications.ResNet50(include_top=False, weights=None, pooling='avg', input_shape=(32, 32, 3))\n",
        "    return base_model\n",
        "\n",
        "class SimCLR(tf.keras.Model):\n",
        "    def __init__(self, projection_dim=128):\n",
        "        super(SimCLR, self).__init__()\n",
        "        self.encoder = get_backbone()\n",
        "        self.projection_head = ProjectionHead(input_dim=2048, proj_dim=projection_dim)\n",
        "        # Note: ResNet50 outputs 2048-dimensional features.\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        h = self.encoder(x, training=training)\n",
        "        z = self.projection_head(h, training=training)\n",
        "        return z\n",
        "\n",
        "# 5. Contrastive Loss (NT-Xent Loss)\n",
        "def contrastive_loss(z1, z2, temperature=0.07):\n",
        "    batch_size = tf.shape(z1)[0]\n",
        "    # Concatenate embeddings\n",
        "    z = tf.concat([z1, z2], axis=0)  # shape: [2*batch_size, feature_dim]\n",
        "    # Compute similarity matrix\n",
        "    sim_matrix = tf.matmul(z, z, transpose_b=True) / temperature  # shape: [2B, 2B]\n",
        "\n",
        "    # Create mask to remove similarity of samples with themselves\n",
        "    logits_mask = tf.linalg.diag(tf.ones(2 * batch_size)) * -1e9\n",
        "    sim_matrix = sim_matrix + logits_mask\n",
        "\n",
        "    # Create labels: for sample i in the first half, positive is i+batch_size; for the second half, positive is i-batch_size\n",
        "    labels = tf.concat([tf.range(batch_size, 2 * batch_size), tf.range(0, batch_size)], axis=0)\n",
        "\n",
        "    # For each sample, compute logits and apply cross-entropy loss.\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, sim_matrix, from_logits=True)\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "# 6. Training Loop\n",
        "if __name__ == \"__main__\":\n",
        "    # Set up distributed strategy if needed.\n",
        "    device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "    with tf.device(device):\n",
        "        # Prepare dataset\n",
        "        train_dataset = prepare_dataset(batch_size=256)\n",
        "\n",
        "        # Define model and optimizer\n",
        "        model = SimCLR(projection_dim=128)\n",
        "        optimizer = optimizers.Adam(learning_rate=5e-4)\n",
        "\n",
        "        # Training parameters\n",
        "        epochs = 10\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0.0\n",
        "            steps = 0\n",
        "            for (x1, x2) in train_dataset:\n",
        "                with tf.GradientTape() as tape:\n",
        "                    # Forward pass for both augmentations\n",
        "                    z1 = model(x1, training=True)\n",
        "                    z2 = model(x2, training=True)\n",
        "                    loss = contrastive_loss(z1, z2, temperature=0.07)\n",
        "                gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                total_loss += loss.numpy()\n",
        "                steps += 1\n",
        "            print(f\"Epoch {epoch+1}, Loss: {total_loss/steps:.4f}\")\n"
      ],
      "metadata": {
        "id": "S-ymibQVaRtL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMwuVKOjdzUkzTZ8y9yQ7AQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}